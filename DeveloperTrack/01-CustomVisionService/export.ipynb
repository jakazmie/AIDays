{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export a model\n",
    "\n",
    "\n",
    "In this section of the lab you will export the trained model and learn how to use it in your application. \n",
    "Custom Vision Service allows classifiers to be exported to run offline. You can embed your exported classifier into an application and run it locally on a device for real-time classification.\n",
    "\n",
    "Custom Vision Service supports the following exports:\n",
    "\n",
    "- Tensorflow for Android.\n",
    "- CoreML for iOS11.\n",
    "- ONNX for Windows ML.\n",
    "- A Windows or Linux container. The container includes a Tensorflow model and service code to use the Custom Vision Service API.\n",
    "\n",
    "Custom Vision Service only exports compact domains. The models generated by compact domains are optimized for the constraints of real-time classification on low powered devices. Classifiers built with a compact domain may be slightly less accurate than a standard domain with the same amount of training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "Install `wget` package that will be used later in the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Custom Vision Service SDK  in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with a compact domain\n",
    "If your classifier was not trained with the compact domain (which is the case for the classifier trained during the first stage of the lab) you need to retrain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_key = 'b1cbbf0f9a054ef481113c9efec1fe4d'\n",
    "prediction_key = 'b01851d0bbe24e9ba3c542ce84306787'\n",
    "project_name = 'AerialClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageUrlCreateEntry\n",
    "\n",
    "trainer = training_api.TrainingApi(training_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the project's domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'id': 'ee85a74c-405e-4adc-bb47-ffa8ca0c9f31', 'name': 'General', 'type': 'Classification', 'exportable': False, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': 'c151d5b5-dd07-472a-acc8-15d29dea8518', 'name': 'Food', 'type': 'Classification', 'exportable': False, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': 'ca455789-012d-4b50-9fec-5bb63841c793', 'name': 'Landmarks', 'type': 'Classification', 'exportable': False, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': 'b30a91ae-e3c1-4f73-a81e-c270bff27c39', 'name': 'Retail', 'type': 'Classification', 'exportable': False, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': '45badf75-3591-4f26-a705-45678d3e9f5f', 'name': 'Adult', 'type': 'Classification', 'exportable': False, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': '0732100f-1a38-4e49-a514-c9b44c697ab5', 'name': 'General (compact)', 'type': 'Classification', 'exportable': True, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': 'b5cfd229-2ac7-4b2b-8d0a-2b0661344894', 'name': 'Landmarks (compact)', 'type': 'Classification', 'exportable': True, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': '6b4faeda-8396-481b-9f8b-177b9fa3097f', 'name': 'Retail (compact)', 'type': 'Classification', 'exportable': True, 'enabled': True}\n",
      "{'additional_properties': {}, 'id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'name': 'General', 'type': 'ObjectDetection', 'exportable': False, 'enabled': True}\n"
     ]
    }
   ],
   "source": [
    "# Print the list of available domains\n",
    "for domain in trainer.get_domains():\n",
    " print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found domain: General (compact)  with ID: 0732100f-1a38-4e49-a514-c9b44c697ab5\n"
     ]
    }
   ],
   "source": [
    "# Find the ID of General (compact) domain\n",
    "domain_name = 'General (compact)'\n",
    "domain_id = None\n",
    "for domain in trainer.get_domains():\n",
    "    if domain.name == domain_name:\n",
    "        domain_id = domain.id\n",
    "        print(\"Found domain: {}  with ID: {}\".format(domain_name,domain_id))\n",
    "        break\n",
    "\n",
    "if domain_id == None:\n",
    "    print(\"Could not find domain: {}\".format(domain_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found project: b98fe4b6-18c1-4044-9788-899ec511a30f\n"
     ]
    }
   ],
   "source": [
    "# Find you project's ID\n",
    "project_id = None\n",
    "project = None\n",
    "for prj in trainer.get_projects():\n",
    "    if prj.name == project_name:\n",
    "        project_id = prj.id\n",
    "        project = prj\n",
    "        print(\"Found project: {0}\".format(project_id))\n",
    "        break\n",
    "        \n",
    "if project_id == None:\n",
    "    print(\"Could not find your project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the project's domain\n",
    "project.settings.domain_id = domain_id\n",
    "project = trainer.update_project(project_id, project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(training_key, project_id):\n",
    "    trainer = training_api.TrainingApi(training_key)\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        iteration = trainer.train_project(project_id)\n",
    "        while (iteration.status != \"Completed\"):\n",
    "            time.sleep(2)\n",
    "            iteration = trainer.get_iteration(project_id, iteration.id)\n",
    "            print (\"Training status: \" + iteration.status)      \n",
    "        # The iteration is now trained. Make it the default project endpoint\n",
    "        print(\"Training completed\")\n",
    "        trainer.update_iteration(project_id, iteration.id, is_default=True)\n",
    "    except:\n",
    "        print(\"No need to retrain. Retrieving default iteration\")\n",
    "        for iteration in trainer.get_iterations(project_id):\n",
    "            if iteration.is_default:\n",
    "                break\n",
    "\n",
    "    return iteration.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "No need to retrain. Retrieving default iteration\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "iteration_id = train(training_key, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the iteration\n",
    "Exporting a model is a two-step process. First you must request the export. It is an asynchronous call. You have to periodically check the status of the request and when the export package is ready you can download it using the returned URI.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request the export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting export for Iteration ID: 4cda13d8-cc40-4a83-8af3-437d7ef8012a\n",
      "Export status: Exporting\n",
      "Export status: Exporting\n",
      "Export package ready. Download URI: {} https://irisscuprodstore.blob.core.windows.net/m-b98fe4b618c140449788899ec511a30f/4cda13d8cc404a838af3437d7ef8012a.TensorFlow.zip?sv=2017-04-17&sr=b&sig=662Vg%2FeUjyK3g9iqcJj8LtrM8iSv%2BeZk5V433V1924I%3D&se=2018-10-14T17%3A49%3A50Z&sp=r\n"
     ]
    }
   ],
   "source": [
    "print(\"Requesting export for Iteration ID: {0}\".format(iteration_id))\n",
    "\n",
    "platform = 'TensorFlow'\n",
    "flavor = 'Linux'\n",
    "\n",
    "export = trainer.export_iteration(project_id, iteration_id, platform, flavor)\n",
    "while (export.status != 'Done'):\n",
    "   print (\"Export status: \" + export.status)\n",
    "   time.sleep(2)\n",
    "   export = trainer.get_exports(project_id, iteration_id)[0]\n",
    "\n",
    "print(\"Export package ready. Download URI: {}\", export.download_uri)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from: https://irisscuprodstore.blob.core.windows.net/m-b98fe4b618c140449788899ec511a30f/4cda13d8cc404a838af3437d7ef8012a.TensorFlow.zip?sv=2017-04-17&sr=b&sig=662Vg%2FeUjyK3g9iqcJj8LtrM8iSv%2BeZk5V433V1924I%3D&se=2018-10-14T17%3A49%3A50Z&sp=r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aerialclassifier.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "download_filename = 'aerialclassifier.zip'\n",
    "\n",
    "print(\"Downloading from: {0}\".format(export.download_uri))\n",
    "wget.download(export.download_uri, download_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  aerialclassifier.zip\n",
      "  inflating: model.pb                \n",
      "  inflating: labels.txt              \n",
      "total 97648\n",
      "-rw-r--r--   1 jarekk  staff      2844 Oct 13 07:40 README.md\n",
      "drwxr-xr-x   4 jarekk  staff       128 Oct 13 09:18 aerial\n",
      "-rw-r--r--@  1 jarekk  staff  37416592 Oct  7 15:28 aerial.zip\n",
      "-rw-r--r--   1 jarekk  staff   2701621 Oct 13 10:12 aerialclassifier (1).pb\n",
      "-rw-r--r--   1 jarekk  staff   2701628 Oct 13 09:59 aerialclassifier.pb\n",
      "-rw-r--r--   1 jarekk  staff   2701610 Oct 13 10:50 aerialclassifier.zip\n",
      "-rw-r--r--@  1 jarekk  staff     10553 Oct 13 10:49 export.ipynb\n",
      "-rw-r--r--   1 jarekk  staff      1878 Oct 13 07:40 export.md\n",
      "drwxr-xr-x  27 jarekk  staff       864 Oct 11 08:05 images\n",
      "-rw-r--r--   1 jarekk  staff        29 Oct 13  2018 labels.txt\n",
      "-rw-r--r--   1 jarekk  staff   2920077 Oct 13  2018 model.pb\n",
      "-rw-r--r--   1 jarekk  staff       886 Oct 11 08:05 predict.md\n",
      "drwxr-xr-x   6 jarekk  staff       192 Oct 13 08:39 samples\n",
      "drwxr-xr-x  11 jarekk  staff       352 Oct 13 10:47 test_images\n",
      "-rw-r--r--   1 jarekk  staff      4093 Oct 13 07:40 train.md\n",
      "-rw-r--r--   1 jarekk  staff   1085320 Oct 13 10:50 train_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "unzip aerialclassifier.zip\n",
    "ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TensorFlow model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /anaconda3/lib/python3.6/site-packages (1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (39.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.5.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.14.3)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py in /anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow) (2.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /anaconda3/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (0.14.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pillow in /anaconda3/lib/python3.6/site-packages (5.1.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.6/site-packages (1.14.3)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/67/150d84f30a8cc6e2af20bc06d5db156ccde03e0922196383086cceaa253b/opencv_python-3.4.3.18-cp36-cp36m-macosx_10_6_x86_64.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (42.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 42.3MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /anaconda3/lib/python3.6/site-packages (from opencv-python) (1.14.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-3.4.3.18\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install pillow\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your model and tags\n",
    "\n",
    "The downloaded zip file contains a model.pb and a labels.txt. These files represent the trained model and the classification labels. The first step is to load the model into your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "filename = 'model.pb'\n",
    "labels_filename = 'labels.txt'\n",
    "\n",
    "graph_def = tf.GraphDef()\n",
    "labels = []\n",
    "\n",
    "# Import the TF graph\n",
    "with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "# Create a list of labels.\n",
    "with open(labels_filename, 'rt') as lf:\n",
    "    for l in lf:\n",
    "        labels.append(l.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare an image for prediction\n",
    "There are a few steps for preparing the image so that it's the right shape for prediction. The model requires images to be BGR format of size (227, 227). Our testing images are RGB of size (224, 224) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=224x224 at 0xB193ABC18>\n",
      "<PIL.Image.Image image mode=RGB size=227x227 at 0xB193ABC88>\n",
      "Numpy array mode=BGR shape=(227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load from a file\n",
    "imageFile = \"test_images/developed-1.png\"\n",
    "image = Image.open(imageFile)\n",
    "print(image\n",
    "     )\n",
    "# Resize \n",
    "image = image.resize((227, 227), resample = Image.BILINEAR)\n",
    "print(image)\n",
    "\n",
    "# Convert to numpy array - tensor\n",
    "image_tensor = np.asarray(image)\n",
    "\n",
    "# Convert RGB -> BGR \n",
    "r,g,b = np.array(image_tensor).T\n",
    "image_tensor = np.array([b,g,r]).transpose()\n",
    "\n",
    "print(\"Numpy array mode=BGR shape={}\".format(image_tensor.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict an image\n",
    "Once the image is prepared as a tensor we can send it through the model for a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8909979e-10 1.6844791e-05 9.9563098e-01]\n"
     ]
    }
   ],
   "source": [
    "# These names are part of the model and cannot be changed.\n",
    "output_layer = 'loss:0'\n",
    "input_node = 'Placeholder:0'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    prob_tensor = sess.graph.get_tensor_by_name(output_layer)\n",
    "    predictions, = sess.run(prob_tensor, {input_node: [image_tensor] })\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results\n",
    "The results of running the image tensor through the model will then need to be mapped back to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as: Developed\n",
      "\n",
      "Barren 0.0\n",
      "Cultivated 1.6840000171214342e-05\n",
      "Developed 0.9956309795379639\n"
     ]
    }
   ],
   "source": [
    "# Print the highest probability label\n",
    "highest_probability_index = np.argmax(predictions)\n",
    "print('Classified as: ' + labels[highest_probability_index])\n",
    "print()\n",
    "\n",
    "# Or you can print out all of the results mapping labels to probabilities.\n",
    "label_index = 0\n",
    "for p in predictions:\n",
    "    truncated_probablity = np.float64(np.round(p,8))\n",
    "    print (labels[label_index], truncated_probablity)\n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
