{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Export a model\n",
    "\n",
    "\n",
    "In this section of the lab you will export the trained model and learn how to use it in your application. \n",
    "Custom Vision Service allows classifiers to be exported to run offline. You can embed your exported classifier into an application and run it locally on a device for real-time classification.\n",
    "\n",
    "Custom Vision Service supports the following exports:\n",
    "\n",
    "- Tensorflow for Android.\n",
    "- CoreML for iOS11.\n",
    "- ONNX for Windows ML.\n",
    "- A Windows or Linux container. The container includes a Tensorflow model and service code to use the Custom Vision Service API.\n",
    "\n",
    "Custom Vision Service only exports compact domains. The models generated by compact domains are optimized for the constraints of real-time classification on low powered devices. Classifiers built with a compact domain may be slightly less accurate than a standard domain with the same amount of training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "Install `wget` package that will be used later in the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Custom Vision Service SDK  in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve your training and prediction keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_key = '<your training key>'\n",
    "prediction_key = '<your prediction key>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `trainer` object using your keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageUrlCreateEntry\n",
    "\n",
    "trainer = training_api.TrainingApi(training_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with a compact domain\n",
    "If your classifier was not trained with the compact domain (which is the case for the classifier trained during the first stage of the lab) you need to retrain it.\n",
    "\n",
    "When you first created your project, it was configured with the `General` domain. A domain represents a pre-trained deep neural network that will be used as a base of your custom image classifier. Each domain optimizes the classifier for specific types of images. `General` is optimized for a broad range of classification tasks. If none of the other domains (`Food`, `Landmarks`, `Retail`, `Adult`) are appropriate, or you are unsure of which domain to choose, select the `General` domain.\n",
    "\n",
    "The compact domains are optimized for the constraints of real-time classification on low powered and mobile devices. The models generated by compact domains can be exported to run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of available domains\n",
    "for domain in trainer.get_domains():\n",
    " print(domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find the ID of the `General (compact)` domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ID of General (compact) domain\n",
    "domain_name = 'General (compact)'\n",
    "domain_id = None\n",
    "for domain in trainer.get_domains():\n",
    "    if domain.name == domain_name:\n",
    "        domain_id = domain.id\n",
    "        print(\"Found domain: {}  with ID: {}\".format(domain_name,domain_id))\n",
    "        break\n",
    "\n",
    "if domain_id == None:\n",
    "    print(\"Could not find domain: {}\".format(domain_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next find your project's ID using your project's name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find you project's ID\n",
    "project_name = 'AerialClassifier'\n",
    "\n",
    "project_id = None\n",
    "project = None\n",
    "for prj in trainer.get_projects():\n",
    "    if prj.name == project_name:\n",
    "        project_id = prj.id\n",
    "        project = prj\n",
    "        print(\"Found project: {0}\".format(project_id))\n",
    "        break\n",
    "        \n",
    "if project_id == None:\n",
    "    print(\"Could not find your project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, change the domain of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the project's domain\n",
    "project.settings.domain_id = domain_id\n",
    "project = trainer.update_project(project_id, project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain\n",
    "\n",
    "You will use the same helper function you used in Part 1 of the lab to retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(training_key, project_id):\n",
    "    trainer = training_api.TrainingApi(training_key)\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        iteration = trainer.train_project(project_id)\n",
    "        while (iteration.status != \"Completed\"):\n",
    "            time.sleep(2)\n",
    "            iteration = trainer.get_iteration(project_id, iteration.id)\n",
    "            print (\"Training status: \" + iteration.status)      \n",
    "        # The iteration is now trained. Make it the default project endpoint\n",
    "        print(\"Training completed\")\n",
    "        trainer.update_iteration(project_id, iteration.id, is_default=True)\n",
    "    except:\n",
    "        print(\"No need to retrain. Retrieving default iteration\")\n",
    "        for iteration in trainer.get_iterations(project_id):\n",
    "            if iteration.is_default:\n",
    "                break\n",
    "\n",
    "    return iteration.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "iteration_id = train(training_key, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the iteration\n",
    "Exporting a model is a two-step process. First you must request an export. It is an asynchronous call. After you requested the export, you should periodically check the status of the request and when the export package is ready you can download it using the returned URI.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request the export and wait for till it is fulfilled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Requesting export for Iteration ID: {0}\".format(iteration_id))\n",
    "\n",
    "platform = 'TensorFlow'\n",
    "flavor = 'Linux'\n",
    "\n",
    "export = trainer.export_iteration(project_id, iteration_id, platform, flavor)\n",
    "while (export.status != 'Done'):\n",
    "   print (\"Export status: \" + export.status)\n",
    "   time.sleep(1)\n",
    "   export = trainer.get_exports(project_id, iteration_id)[0]\n",
    "\n",
    "print(\"Export package ready. Download URI: {}\", export.download_uri)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can download the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "download_filename = 'aerialclassifier.zip'\n",
    "\n",
    "print(\"Downloading from: {0}\".format(export.download_uri))\n",
    "wget.download(export.download_uri, download_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package has been exported as a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "unzip aerialclassifier.zip\n",
    "ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains two files: `model.pb` and `labels.txt`. These files represent the trained model and the classification labels. The model has been exported in TensorFlow protocol buffers format. You will need TensorFlow runtime to execute model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TensorFlow model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install TensorFlow and other dependencies required to load and run your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow==1.7\n",
    "!{sys.executable} -m pip install pillow\n",
    "!{sys.executable} -m pip install numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now load the saved model to a TensorFlow computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "filename = 'model.pb'\n",
    "labels_filename = 'labels.txt'\n",
    "\n",
    "graph_def = tf.GraphDef()\n",
    "labels = []\n",
    "\n",
    "# Import the TF graph\n",
    "with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "# Create a list of labels.\n",
    "with open(labels_filename, 'rt') as lf:\n",
    "    for l in lf:\n",
    "        labels.append(l.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare an image for prediction\n",
    "\n",
    "There are a few steps for preparing the image so that it's the right shape for prediction. The exported model requires images to be BGR format of size (227, 227). Our testing images are RGB of size (224, 224) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load from a file\n",
    "imageFile = \"test_images/developed-1.png\"\n",
    "image = Image.open(imageFile)\n",
    "print(image\n",
    "     )\n",
    "# Resize \n",
    "image = image.resize((227, 227), resample = Image.BILINEAR)\n",
    "print(image)\n",
    "\n",
    "# Convert to numpy array - tensor\n",
    "image_tensor = np.asarray(image)\n",
    "\n",
    "# Convert RGB -> BGR \n",
    "r,g,b = np.array(image_tensor).T\n",
    "image_tensor = np.array([b,g,r]).transpose()\n",
    "\n",
    "print(\"Numpy array mode=BGR shape={}\".format(image_tensor.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict an image\n",
    "Once the image is prepared as a tensor of the required shape and format, we can send it through the model for a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These names are part of the model and cannot be changed.\n",
    "output_layer = 'loss:0'\n",
    "input_node = 'Placeholder:0'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    prob_tensor = sess.graph.get_tensor_by_name(output_layer)\n",
    "    predictions, = sess.run(prob_tensor, {input_node: [image_tensor] })\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the results\n",
    "The result of running the image tensor through the model is a vector of probabilities of the image belonging to each of the classes. To make the result more readable you will map it back to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the highest probability label\n",
    "highest_probability_index = np.argmax(predictions)\n",
    "print('Classified as: ' + labels[highest_probability_index])\n",
    "print()\n",
    "\n",
    "# Or you can print out all of the results mapping labels to probabilities.\n",
    "label_index = 0\n",
    "for p in predictions:\n",
    "    truncated_probablity = np.float64(np.round(p,8))\n",
    "    print (labels[label_index], truncated_probablity)\n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you exported the trained model and then used it in Python script for inference - a.k.a predictions. As you have seen, you can embedded your model in an arbitrary application. TensorFlow APIs are available in several languages besides Python, including JavaScript, C++, Java, Go, and Swift. In addition, you can use TensorFlow Serving and Azure Machine Learning service for model deployment in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
