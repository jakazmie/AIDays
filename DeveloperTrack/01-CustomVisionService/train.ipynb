{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Train, evaluate, and test\n",
    "\n",
    "In this part of the lab you will use Custom Vision Python SDK to train, evaluate, fine tune, and test the custom image classification model described in the introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab setup\n",
    "\n",
    "Before proceeding with the lab you need to install Custom Vision Service SDK into your notebook's kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Custom Vision Service SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Custom Vision Service SDK  in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the training and prediction keys\n",
    "\n",
    "To invoke Custom Vision API you will need access keys.\n",
    "\n",
    "To get the keys, navigate to the resource group you created during the lab setup and retrieve the keys for both training and prediction services. The keys can be grabbed from the overview page of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "\n",
    "training_key = '<your training key>'\n",
    "prediction_key = '<your prediction key>'\n",
    "\n",
    "trainer = training_api.TrainingApi(training_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Custom Vision Service project\n",
    "\n",
    "A Custom Vision Service project is a container for the artifacts used during model development, including training data and training runs. You have to create a seperate project for each model you want to develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the name for your project\n",
    "project_name = 'AerialClassifier'\n",
    "\n",
    "# Check if the project with that name exists\n",
    "project_id = None\n",
    "for project in trainer.get_projects():\n",
    "    if project.name == project_name:\n",
    "        project_id = project.id\n",
    "        print(\"Found existing project: {0}\".format(project_id))\n",
    "        break\n",
    "# Create a new project        \n",
    "if project_id == None:\n",
    "    print(\"Creating a new project\")\n",
    "    project = trainer.create_project(project_name)\n",
    "    project_id = project.id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "As described in the intro to the lab, you will train the model on ~500 images representing 3 types of land: `Barren`, `Cultivated`, and `Developed`.\n",
    "\n",
    "The training images can be uploaded from the public Azure blob container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get example images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/aerial.zip\n",
    "unzip aerial.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to your project\n",
    "You need to add tags to your project before you can label and upload your training images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tags. Check for existing tags before creating new ones\n",
    "tags = trainer.get_tags(project_id)\n",
    "if len(tags) == 0:\n",
    "    tags = [trainer.create_tag(project_id, tag) for tag in ['Barren', 'Developed', 'Cultivated']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag and upload images\n",
    "\n",
    "The API used to upload images `create_images_from_files` uploads a batch of images at a time. The maximum supported batch size is 64. To simplify the upload process we created a utility function `upload_images` that manages batch creation and upload.\n",
    "\n",
    "The input to the function is the list of Python tuples, where each tuple represents a single image and consists of the Tag ID (that refers to the tag describing the image) and the path to the image on your local file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "\n",
    "# Define a utility function to upload a list of images\n",
    "def upload_images(training_key, project_id, image_list, batch_size=64):\n",
    "    trainer = training_api.TrainingApi(training_key)\n",
    "    print(\"Starting upload ...\")\n",
    "    image_batches = [image_list[start: start+batch_size] for start in range(0, len(image_list), batch_size)]\n",
    "    for batch in image_batches:\n",
    "        image_entry_batch = []\n",
    "        for tag, pathname, file_name in batch:\n",
    "            with open(pathname, mode='rb') as image_contents:\n",
    "                image_entry_batch.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[tag]))\n",
    "        summary = trainer.create_images_from_files(project_id, images=image_entry_batch)\n",
    "    print(\"Done.\")\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Upload images\n",
    "base_folder = 'aerial/train'\n",
    "# Create a dictionary mapping tag names to tag ids\n",
    "tag_map = {tag.name: tag.id for tag in tags}\n",
    "# Create an input list to upload_images function\n",
    "image_list = [(tag_map[folder], os.path.join(base_folder, folder, filename), filename)  for folder in ['Barren','Cultivated', 'Developed'] for filename in os.listdir(os.path.join(base_folder, folder))]\n",
    "# Start the upload\n",
    "summary = upload_images(training_key, project_id, image_list, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the first iteration of the project\n",
    "\n",
    "You will repeat the training a couple of times during the lab. To simplify the process we created a helper function that encapsulates training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(training_key, project_id):\n",
    "    trainer = training_api.TrainingApi(training_key)\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        iteration = trainer.train_project(project_id)\n",
    "        while (iteration.status != \"Completed\"):\n",
    "            time.sleep(2)\n",
    "            iteration = trainer.get_iteration(project_id, iteration.id)\n",
    "            print (\"Training status: \" + iteration.status)      \n",
    "        # The iteration is now trained. Make it the default project endpoint\n",
    "        print(\"Training completed\")\n",
    "        trainer.update_iteration(project_id, iteration.id, is_default=True)\n",
    "    except:\n",
    "        print(\"No need to retrain. Retrieving default iteration\")\n",
    "        for iteration in trainer.get_iterations(project_id):\n",
    "            if iteration.is_default:\n",
    "                break\n",
    "\n",
    "    return iteration.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time you invoke training a new iteration is created. An iteration is a Custom Vision Service object that encapsulates training data, trained model, and performance measures for a  training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "iteration_id = train(training_key, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get iteration performance \n",
    "\n",
    "After the training run has completed, you can retrieve perfomance measures for the iteration. We defined a helper function `display_iteration_performance` that encapsulates the call to the service and formatting of the ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_iteration_performance(training_key, project_id, iteration_id):\n",
    "    trainer = training_api.TrainingApi(training_key)\n",
    "    performance = trainer.get_iteration_performance(project_id, iteration_id)\n",
    "    print(\"Overall Precision: {0:<10}\".format(performance.precision))\n",
    "    print(\"Overall Recall:    {0:<10}\".format(performance.recall))\n",
    "    for tag_perf in performance.per_tag_performance:\n",
    "        print(\"Tag: {0:<15} Precision: {1:<10}   Recall: {2:<10}\".format(tag_perf.name, tag_perf.precision, tag_perf.recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_iteration_performance(training_key, project_id, iteration_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve your classifier\n",
    "\n",
    "The quality of your classifier is dependent on the amount, quality, and variety of the labeled data you provide to it and how balanced the dataset is. A good classifier normally has a balanced training dataset that is representative of what will be submitted to the classifier. The process of building such a classifier is \n",
    "iterative. It's common to take a few rounds of training to reach expected results. As you track the performance of your model you may add more images of the underperforming class or augment your existing images by varying lighting, cropping, color saturation, etc.\n",
    "\n",
    "In the next step you will add more images of  `Developed`  land plots and retrain the model to create the new iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload images\n",
    "base_folder = 'aerial/train'\n",
    "folder = 'Developed-SecondBatch'\n",
    "image_list = [(tag_map['Developed'], os.path.join(base_folder, folder, filename), filename)  for filename in os.listdir(os.path.join(base_folder, folder))]\n",
    "\n",
    "summary = upload_images(training_key, project_id, image_list, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "iteration_id = train(training_key, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_iteration_performance(training_key, project_id, iteration_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Your model is ready. Each time you run training, Custom Vision Service automatically creates a REST API wrapper - prediction endpoint - around the model created by a training run. You can use it immediately after the run has completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir test_images\n",
    "cd test_images\n",
    "wget -nv https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/barren-1.png\n",
    "wget -nv https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/cultivated-1.png\n",
    "wget -nv https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/developed-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display test images\n",
    "\n",
    "The images we will use for testing have been downloaded to the `test_imags` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "images_dir = 'test_images'\n",
    "images = [os.path.join(images_dir, file) for file in os.listdir(images_dir)]\n",
    "\n",
    "figsize=(10, 8)\n",
    "fig, axis = plt.subplots(len(images)//3, 3, figsize=figsize)\n",
    "fig.tight_layout()\n",
    "for ax, image_path in zip(axis.flat[0:], images):\n",
    "    image = Image.open(image_path)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Test with `curl`\n",
    " \n",
    " As noted, the prediction endpoint is a REST API that can be accessed using any tool capable of formatting REST requests, including a command line tool `curl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECT_ID=$project_id\n",
    "%env PREDICTION_KEY=$prediction_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "curl -X POST https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/$PROJECT_ID/image -H \"Prediction-Key: $PREDICTION_KEY\"  -H \"Content-Type: application/octet-stream\" --data-binary @test_images/developed-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the prediction endpoint using Python SDK\n",
    "\n",
    "From Python, you can invoke the prediction endpoint using `urllib` or other library for working with HTTP. However, it is even easier to use Custom Vision Service Python SDK.\n",
    "\n",
    "Python SDK wraps the prediction endpoint in the `prediction_endpoint` class. The class exposes the `predict_image` method that takes a Python File Object as parameter. The following code snippet defines a utility function `classify_image` that invokes the prediction endpoint and parses the results returned from the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import prediction_endpoint\n",
    "from azure.cognitiveservices.vision.customvision.prediction.prediction_endpoint import models\n",
    "\n",
    "def classify_image(project_id, prediction_key, image_path):\n",
    "    predictor = prediction_endpoint.PredictionEndpoint(prediction_key)\n",
    "    with open(image_path, mode='rb') as image:\n",
    "      result = predictor.predict_image(project_id, image)    \n",
    "    probs = [prediction.probability for prediction in result.predictions]\n",
    "    max_prob = max(probs)\n",
    "    max_index = probs.index(max_prob)\n",
    "    tag = result.predictions[max_index].tag_name\n",
    "\n",
    "    return tag, max_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now invoke the prediction endpoint and display the results returned by the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(10, 8)\n",
    "fig, axis = plt.subplots(len(images)//3, 3, figsize=figsize)\n",
    "fig.tight_layout()\n",
    "for ax, image_path in zip(axis.flat[0:], images):\n",
    "    tag, prob = classify_image(project_id, prediction_key, image_path)\n",
    "    ax.set_title(tag + ': ' + str(prob))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    image = Image.open(image_path)\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this part of the lab you learned how to train, evaluate and improve your custom image classification model. In the second part of the lab, you will learn how to export and operationalize your trained model.\n",
    "\n",
    "To proceed to Part II, open `export.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
