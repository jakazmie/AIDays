{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the prediction endpoint\n",
    "This notebook demonstrates how use the REST prediction endpoint to remotely access a custom image classification model you trained in the previous step of the lab. \n",
    "\n",
    "Note that the prediction endpoint is a REST web service and as such can be easily accessed using any tool and programming environment supporting REST interfaces. For example you can invoke the service using `curl` utility in Linux.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir test_images\n",
    "cd test_images\n",
    "wget https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/barren-1.png\n",
    "wget https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/cultivated-1.png\n",
    "wget  https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/developed-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the prediction key and project id\n",
    "Before you can access the endpoint you need to retrieve project id and prediction key. If you want to access a specific iteration you will also need Iteration ID. If you don't specify Iteration ID the call will be routed to the default iteration.\n",
    "\n",
    "To get the keys, navigate to the Custom Vision web page and select the gear icon in the upper right. In the Accounts section, copy the value from the Prediction Key field.\n",
    "\n",
    "![Keys](https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/images/img13.PNG)\n",
    "\n",
    "\n",
    "Change the values below to your project's keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECT_ID=<your project ID>\n",
    "%env PREDICTION_KEY=<your prediction key>\n",
    "\n",
    "PROJECT_ID = %env PROJECT_ID\n",
    "PREDICTION_KEY = %env PREDICTION_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "curl -X POST https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/$PROJECT_ID/image -H \"Prediction-Key: $PREDICTION_KEY\"  -H \"Content-Type: application/octet-stream\" --data-binary @test_images/developed-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify integration with your applications, Custom Vision Service provides SDKs that wrap REST APIs, including the prediction endpoint, in easy to use libraries. Currently, C#, Go, and Python SDKs are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Custom Vision Service SDK\n",
    "\n",
    "Before proceeding we will install Custom Vistion Service SDK from PyPI. If you are running this notebook in the Python environment that has the SDK pre-installed you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Custom Vision Service SDK  in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install azure-cognitiveservices-vision-customvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display test images\n",
    "\n",
    "The images we will use for testing are located in the `samples` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "images_dir = 'test_images'\n",
    "images = [os.path.join(images_dir, file) for file in os.listdir(images_dir)]\n",
    "\n",
    "figsize=(10, 8)\n",
    "fig, axis = plt.subplots(len(images)//3, 3, figsize=figsize)\n",
    "fig.tight_layout()\n",
    "for ax, image_path in zip(axis.flat[0:], images):\n",
    "    image = Image.open(image_path)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the prediction endpoint\n",
    "\n",
    "Python SDK wraps the prediction endpoint in the `prediction_endpoint` class. The class exposes the `predict_image` method that takes a Python File Object as parameter. The following code snippet defines a utility function `classify_image` that invokes the prediction endpoint and parses the results returned from the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import prediction_endpoint\n",
    "from azure.cognitiveservices.vision.customvision.prediction.prediction_endpoint import models\n",
    "\n",
    "def classify_image(image_path):\n",
    "    predictor = prediction_endpoint.PredictionEndpoint(PREDICTION_KEY)\n",
    "    with open(image_path, mode='rb') as image:\n",
    "      result = predictor.predict_image(PROJECT_ID, image)\n",
    "    \n",
    "    probs = [prediction.probability for prediction in result.predictions]\n",
    "    max_prob = max(probs)\n",
    "    max_index = probs.index(max_prob)\n",
    "    tag = result.predictions[max_index].tag_name\n",
    "\n",
    "    return tag, max_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now invoke the prediction endpoint and display the results returned by the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(10, 8)\n",
    "fig, axis = plt.subplots(len(images)//3, 3, figsize=figsize)\n",
    "fig.tight_layout()\n",
    "for ax, image_path in zip(axis.flat[0:], images):\n",
    "    tag, prob = classify_image(image_path)\n",
    "    ax.set_title(tag + ': ' + str(prob))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    image = Image.open(image_path)\n",
    "    ax.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
