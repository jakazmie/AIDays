{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Feature Engineering\n",
    "In this section of the lab we will develop and run a Python script that will pre-process training and validation images into a set of powerful features - refered to in the lab as bottleneck features.\n",
    "\n",
    "To create bottleneck features we will utilize a pre-trained Deep Learning network that was trained on a general computer vision domain. \n",
    "\n",
    "As explained by your instructor this approach is called Transfer Learning. Transfer Learning is a powerful Machine Learning technique that is based on an observation that the knowledge gained while solving one problem can be applied to a different (but related problem).\n",
    "\n",
    "In the context of an image classification task, a DNN trained on one visual domain can accelerate learing in another visual domain. Although, our pre-trained network does not know how to classify aerial land plot images, it knows enough about representing image concepts that if we use it to pre-process aerial images, the extracted image features can be used to effectively train a relatively simple classifier on a **limited number** of samples.\n",
    "\n",
    "The below diagram represents the architecture of our solution.\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/TLArch.png)\n",
    "\n",
    "We will use a **ResNet50** trained on **imagenet** dataset to extract features. We will occasionally refer to this component of the solution as a featurizer. The output of the featurizer is a vector of 2048 floating point numbers, each representing a feature extracted from an image. \n",
    "\n",
    "We will then use extracted features to train a simple fully connected neural network (FCNN) to classify aerial land plot images. We could use any other classification algorithm - e.g. logistic regression or decision trees but FCNN gives us a lot flexibility in fine tuning the model.\n",
    "\n",
    "\n",
    "The Python script generated by the next Jupyter cell processes an input image dataset into an output bottleneck feature set. The script expects the images to be organized in the below folder structure:\n",
    "```\n",
    "train/\n",
    "   Barren/\n",
    "   Cultivated/\n",
    "   Developed/\n",
    "   Forest/\n",
    "   Herbaceous/\n",
    "   Shrub/\n",
    "valid/\n",
    "   Barren/\n",
    "   Cultivated/\n",
    "   Developed/\n",
    "   Forest/\n",
    "   Herbaceous/\n",
    "   Shrub/\n",
    "```\n",
    "\n",
    "The location of the input dataset and the location where to save the output dataset are passed to the script as command line parameters. The output dataset will be stored in a binary HDF5 data format used commonly in Machine Learning and High Performance Computing solutions.\n",
    "\n",
    "The script is designed to work with a large number of images. As such it does not load all input images to memory at once. Instead it utilizes custom Python generator class - `ImageGenerator` to feed **ResNet50** featurizer. The class yields batches of images - as Numpy arrays - preprocessed to the format required by **ResNet50**. \n",
    "\n",
    "We will not attempt to run the script in a local environment. It is very computationally intensive and unless you run it in an evironment equipped with a powerful GPU it would be very slow. It would be *painfully* slow if you attempt to run it in Azure Notebooks.\n",
    "\n",
    "Instead we will run the script on a remote Azure GPU VM.\n",
    "\n",
    "Your instructor will dive into the code in the script and explain key snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data pre-processing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a folder to hold the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Jupyter `%%writefile` magic to write the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/extract.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/extract.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# This is a generator that yields batches of preprocessed images\n",
    "class ImageGenerator(tf.keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, img_dir, preprocess_fn=None, batch_size=64):\n",
    "        \n",
    "        # Create the dictionary that maps class names into numeric labels \n",
    "        folders = os.listdir(img_dir)\n",
    "        folders.sort()\n",
    "        indexes = range(len(folders))\n",
    "        label_map = {key: value for (key, value) in zip(folders, indexes)}\n",
    "        self.num_classes = len(label_map)\n",
    "        \n",
    "        # Create a list of all images in a root folder with associated numeric labels\n",
    "        labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                              for folder in folders \n",
    "                              for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                              ]\n",
    "        # Shuffle the list\n",
    "        random.shuffle(labeled_image_list)\n",
    "        # Set image list and associated label list\n",
    "        self.image_list, self.label_list = zip(*labeled_image_list) \n",
    "        # Set batch size\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "        # Set the pre-processing function passed as a parameter\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "        # Set number of batches\n",
    "        self.n_batches = len(self.image_list) // self.batch_size\n",
    "        if len(self.image_list) % self.batch_size > 0:\n",
    "            self.n_batches += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pathnames = self.image_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images = self.__load_images(pathnames)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Load a set of images passed as a parameter into a NumPy array\n",
    "    def __load_images(self, pathnames):\n",
    "        images = []\n",
    "        for pathname in pathnames:\n",
    "            img = image.load_img(pathname, target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        images = np.asarray(images)\n",
    "        if self.preprocess_fn != None:\n",
    "            images = self.preprocess_fn(images)   \n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Return labels in one-hot encoding\n",
    "    def get_labels(self):\n",
    "        \n",
    "        return to_categorical(np.asarray(self.label_list), self.num_classes)\n",
    "    \n",
    "\n",
    "\n",
    "def create_bottleneck_features():\n",
    "    # Configure input directories\n",
    "    train_images_dir = os.path.join(FLAGS.input_data_dir, 'train')\n",
    "    valid_images_dir = os.path.join(FLAGS.input_data_dir, 'valid')\n",
    "\n",
    "    # Create generators for training and validation data\n",
    "    train_generator = ImageGenerator(train_images_dir, resnet50.preprocess_input)\n",
    "    valid_generator = ImageGenerator(valid_images_dir, resnet50.preprocess_input)\n",
    "\n",
    "    # Create a featurizer\n",
    "    featurizer = resnet50.ResNet50(\n",
    "                weights = 'imagenet', \n",
    "                input_shape=(224,224,3), \n",
    "                include_top = False,\n",
    "                pooling = 'avg')\n",
    "\n",
    "    # Generate training bottleneck features\n",
    "    print(\"Generating training bottleneck features\")\n",
    "    features = featurizer.predict_generator(train_generator, verbose=1)\n",
    "    labels = train_generator.get_labels()\n",
    "    \n",
    "    # Save the training dataset to HDF5 file\n",
    "    filename = 'aerial_bottleneck_train.h5'\n",
    "    output_file = os.path.join(FLAGS.output_data_dir, filename)\n",
    "    print(\"Saving training features to {}\".format(output_file))\n",
    "    with h5py.File(output_file, \"w\") as hfile:\n",
    "        features_dset = hfile.create_dataset('features', data=features)\n",
    "        labels_dset = hfile.create_dataset('labels', data=labels)\n",
    "    \n",
    "\n",
    "     # Generate validation bottleneck features\n",
    "    print(\"Generating validation bottleneck features\")\n",
    "    features = featurizer.predict_generator(valid_generator, verbose=1)\n",
    "    labels = valid_generator.get_labels()\n",
    "    \n",
    "    # Save the training dataset to HDF5 file\n",
    "    filename = 'aerial_bottleneck_valid.h5'\n",
    "    output_file = os.path.join(FLAGS.output_data_dir, filename)\n",
    "    print(\"Saving validation features to {}\".format(output_file))\n",
    "    with h5py.File(output_file, \"w\") as hfile:\n",
    "        features_dset = hfile.create_dataset('features', data=features)\n",
    "        labels_dset = hfile.create_dataset('labels', data=labels)\n",
    "    \n",
    "    print(\"Done\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_string('input_data_dir', 'aerialsmall', \"Folder with training and validation images\")\n",
    "tf.app.flags.DEFINE_string('output_data_dir', 'bottleneck', \"A folder for saving bottleneck features\")\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    print(\"Starting\")\n",
    "    print(FLAGS.input_data_dir)\n",
    "    print(FLAGS.output_data_dir)\n",
    "    \n",
    "    print(os.listdir(FLAGS.input_data_dir))\n",
    "    print(os.listdir(FLAGS.output_data_dir))\n",
    "    return\n",
    "\n",
    "    create_bottleneck_features()\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Compute Target\n",
    "Our script is now ready for execution. We will run the script on a single node of a remote GPU cluster. We will use Azure ML Python SDK to create and configure the cluster, datastores, and run configuration.\n",
    "\n",
    "The first step is to intialize the AML workspace you created during the lab overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/demouser/repos/AIDays/DataScientistTrack/02-AML-EndToEndWalkthrough/aml_config/config.json\n",
      "jkaml\n",
      "jkaml\n",
      "southcentralus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Azure Batch AI cluster as a compute target\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in the workspace this code uses it and skips the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a new compute target...\n",
      "Creating\n",
      "succeeded................\n",
      "BatchAI wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'steady', 'allocationStateTransitionTime': '2018-10-14T20:39:45.914000+00:00', 'creationTime': '2018-10-14T20:37:52.520000+00:00', 'currentNodeCount': 1, 'errors': None, 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preparingNodeCount': 1, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'succeeded', 'provisioningStateTransitionTime': '2018-10-14T20:38:06.284000+00:00', 'scaleSettings': {'manual': None, 'autoScale': {'maximumNodeCount': 4, 'minimumNodeCount': 1, 'initialNodeCount': 1}}, 'vmPriority': 'dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "batchai_cluster_name = ws.name + 'gpucluster'\n",
    "\n",
    "try:\n",
    "    # look for the existing cluster by name\n",
    "    compute_target = ComputeTarget(workspace=ws, name=batchai_cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('found compute target {}, just use it.'.format(batchai_cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(batchai_cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\", # GPU-based VM\n",
    "                                                                #vm_priority='lowpriority', # optional\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=1, \n",
    "                                                                cluster_max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, compute_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Datastores \n",
    "The dataset we will use for training is located in a public Azure blob storage container. We will register this container as a datastore within our workspace.\n",
    "\n",
    "The output of the script - bottleneck files - will be pushed to the default datastore that was created automatically when you created your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering datastore failed with 400 error code and error message\n",
      "b'{\\n  \"error\": {\\n    \"code\": \"UserError\",\\n    \"message\": \"Another data store with the same name already exists but with different values. Please use patch to update.\",\\n    \"target\": null,\\n    \"details\": [],\\n    \"innerError\": null,\\n    \"debugInfo\": {\\n      \"type\": \"Microsoft.MachineLearning.Common.WebApi.Exceptions.BadRequestException\",\\n      \"message\": \"Another data store with the same name already exists but with different values. Please use patch to update.\",\\n      \"stackTrace\": \"   at Microsoft.MachineLearning.DataStore.EntryPoints.Controllers.DataStoreController.CreateOrUpdate(DataStoreDto dto, Boolean create, Boolean createIfNotExists) in /home/vsts/work/1/s/src/azureml-api/src/DataStore/EntryPoints/Controllers/DataStoreController.cs:line 120\\\\n   at Microsoft.MachineLearning.DataStore.EntryPoints.Controllers.DataStoreController.Create(DataStoreDto dto, Boolean createIfNotExists) in /home/vsts/work/1/s/src/azureml-api/src/DataStore/EntryPoints/Controllers/DataStoreController.cs:line 59\\\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\\\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\\\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\\\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\\\\n   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()\",\\n      \"innerException\": null,\\n      \"data\": {},\\n      \"errorResponse\": null\\n    }\\n  },\\n  \"correlation\": {\\n    \"operation\": \"e51cd602-4e341a541478c64c\",\\n    \"request\": \"KEkXmA8xtE0=\"\\n  }\\n}'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing datastore for input images: input_images\n",
      "input_images AzureBlob azureailabs aerialsmall\n",
      "Using the default datastore for output: \n",
      "workspacefilestore AzureFile jkamlstoragetuqtsfhp azureml-filestore-9548cf74-fb4f-4c04-85a5-1a93063dc9b5\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "datastore_name = 'input_images'\n",
    "try:\n",
    "    input_ds = Datastore.register_azure_blob_container(workspace=ws, datastore_name=datastore_name,\n",
    "                                            container_name='aerialsmall',\n",
    "                                            account_name='azureailabs')\n",
    "    print('Creating new datastore for input images')\n",
    "except:\n",
    "    input_ds = Datastore(ws, datastore_name)\n",
    "    print('Found existing datastore for input images:', input_ds.name)\n",
    "   \n",
    "print(input_ds.name, input_ds.datastore_type, input_ds.account_name, input_ds.container_name)\n",
    "\n",
    "output_ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for output: \")\n",
    "print(output_ds.name, output_ds.datastore_type, output_ds.account_name, output_ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure data access mode\n",
    "\n",
    "We will now create `DataReferenceConfiguration` objects to inform AML runtime how to access input and output datastores while running the script on the cluster. Since we will be running the script on a single node of the cluster, the most efficient approach is to download the input dataset to the local storage on the node before running the script. The output datastore will be mounted as a remote file system so we can persist the bottleneck feature files outside of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "input_dr = DataReferenceConfiguration(datastore_name=input_ds.name, \n",
    "                                      path_on_datastore=None, \n",
    "                                      path_on_compute=input_ds.name,\n",
    "                                      mode='download', # download files from datastore to compute target\n",
    "                                      overwrite=True)\n",
    "\n",
    "\n",
    "output_dr = DataReferenceConfiguration(datastore_name=output_ds.name,\n",
    "                                       path_on_datastore='bottleneck',\n",
    "                                       path_on_compute=output_ds.name,\n",
    "                                       mode=\"mount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Experiment\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments. We will use **Experiment** to store logs generated by our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'aerial-classifier'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "We are now ready to run the script on the cluster. There are multiple ways to run the job. We are goint to utilize a higher level **Estimator** object and run the script in a docker container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--input_data_dir': input_dr,\n",
    "    '--output_data_dir': output_dr\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                node_count=1,\n",
    "                process_count_per_node=1,\n",
    "                use_gpu=True,\n",
    "                pip_packages=['h5py','pillow','tensorflow-gpu']\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: aerial-classifier_1539548655517\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: aerial-classifier_1539548655517\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'aerial-classifier_1539548655517',\n",
       " 'target': 'gpudsvm',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2018-10-14T20:24:18.563276Z',\n",
       " 'endTimeUtc': '2018-10-14T20:24:45.330709Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'fde3f3aa-cba1-4e1f-907c-dc92233db180'},\n",
       " 'runDefinition': {'Script': 'extract.py',\n",
       "  'Arguments': ['--input_data_dir',\n",
       "   '$AZUREML_DATAREFERENCE_input_images',\n",
       "   '--output_data_dir',\n",
       "   '$AZUREML_DATAREFERENCE_workspacefilestore'],\n",
       "  'Framework': 0,\n",
       "  'Target': 'gpudsvm',\n",
       "  'DataReferences': {'input_images': {'DataStoreName': 'input_images',\n",
       "    'Mode': 'Download',\n",
       "    'PathOnDataStore': None,\n",
       "    'PathOnCompute': 'input_images',\n",
       "    'Overwrite': True},\n",
       "   'workspacefilestore': {'DataStoreName': 'workspacefilestore',\n",
       "    'Mode': 'Download',\n",
       "    'PathOnDataStore': 'bottleneck',\n",
       "    'PathOnCompute': 'workspacefilestore',\n",
       "    'Overwrite': True}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults==0.1.68']},\n",
       "      'tensorflow-gpu',\n",
       "      'h5py',\n",
       "      'pillow']},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.1.4',\n",
       "    'Enabled': False,\n",
       "    'SharedVolumes': True,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 1, 'MemoryGb': 4},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jkamlstoragetuqtsfhp.blob.core.windows.net/azureml/ExperimentRun/aerial-classifier_1539548655517/azureml-logs/60_control_log.txt?sv=2017-04-17&sr=b&sig=MNcMO2w2UGVtS5C2Fjt%2BaaXQnH8GviNqDACHioyxHE0%3D&st=2018-10-14T20%3A30%3A04Z&se=2018-10-15T04%3A40%3A04Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://jkamlstoragetuqtsfhp.blob.core.windows.net/azureml/ExperimentRun/aerial-classifier_1539548655517/azureml-logs/azureml.log?sv=2017-04-17&sr=b&sig=skjv1ImejkZCUvGJP7iIsWfqZuwX%2Fa9yJTKCQc%2FWmrM%3D&st=2018-10-14T20%3A30%3A04Z&se=2018-10-15T04%3A40%3A04Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://jkamlstoragetuqtsfhp.blob.core.windows.net/azureml/ExperimentRun/aerial-classifier_1539548655517/azureml-logs/80_driver_log.txt?sv=2017-04-17&sr=b&sig=N0JbgRU7p0SqgjHyMOjNFRN8JZfEAdXgQ%2BVQIt2qbXw%3D&st=2018-10-14T20%3A30%3A04Z&se=2018-10-15T04%3A40%3A04Z&sp=r'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
