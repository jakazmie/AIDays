{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrate remote training with Azure Machine Learning service\n",
    "\n",
    "\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/amlarch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "subscription_id ='<your subscription id>'\n",
    "resource_group ='<your resource group>'\n",
    "workspace_name = '<your workspace name>'\n",
    "\n",
    "try:\n",
    "   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "\n",
    "   print('Workspace configuration succeeded. You are all set!')\n",
    "except:\n",
    "   print('Workspace not found. Creating...')\n",
    "   workspace_region = 'southcentralus'\n",
    "   ws = Workspace.create(name = workspace_name,\n",
    "                subscription_id = subscription_id,\n",
    "                resource_group = resource_group, \n",
    "                location = workspace_region,\n",
    "                create_resource_group = True,\n",
    "                exist_ok = True)\n",
    "\n",
    "ws.get_details()\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script\n",
    "\n",
    "To submit the job to the cluster, first create a training script. Run the following code to create the training script called `train.py` in the directory you just created. The scripts encapsulates the code we prepared in the first part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "    \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "\n",
    "\n",
    "# This is a generator that yields batches of preprocessed images\n",
    "class ImageGenerator(tf.keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, img_dir, preprocess_fn=None, batch_size=64):\n",
    "        \n",
    "        # Create the dictionary that maps class names into numeric labels \n",
    "        folders = os.listdir(img_dir)\n",
    "        folders.sort()\n",
    "        indexes = range(len(folders))\n",
    "        label_map = {key: value for (key, value) in zip(folders, indexes)}\n",
    "        self.num_classes = len(label_map)\n",
    "        \n",
    "        # Create a list of all images in a root folder with associated numeric labels\n",
    "        labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                              for folder in folders \n",
    "                              for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                              ]\n",
    "        # Shuffle the list\n",
    "        random.shuffle(labeled_image_list)\n",
    "        # Set image list and associated label list\n",
    "        self.image_list, self.label_list = zip(*labeled_image_list) \n",
    "        # Set batch size\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "        # Set the pre-processing function passed as a parameter\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "        # Set number of batches\n",
    "        self.n_batches = len(self.image_list) // self.batch_size\n",
    "        if len(self.image_list) % self.batch_size > 0:\n",
    "            self.n_batches += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pathnames = self.image_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images = self.__load_images(pathnames)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Load a set of images passed as a parameter into a NumPy array\n",
    "    def __load_images(self, pathnames):\n",
    "        images = []\n",
    "        for pathname in pathnames:\n",
    "            img = image.load_img(pathname, target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        images = np.asarray(images)\n",
    "        if self.preprocess_fn != None:\n",
    "            images = self.preprocess_fn(images)   \n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Return labels in one-hot encoding\n",
    "    def get_labels(self):\n",
    "        \n",
    "        return to_categorical(np.asarray(self.label_list), self.num_classes)\n",
    "    \n",
    "\n",
    "def fcn_classifier(input_shape=(2048,), units=512, classes=6,  l1=0.01, l2=0.01):\n",
    "    features = Input(shape=input_shape)\n",
    "    x = Dense(units, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=features, outputs=y)\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_evaluate(run):\n",
    "   \n",
    "    # Create bottleneck featurs\n",
    "    train_images_dir = os.path.join(FLAGS.data_folder, 'train')\n",
    "    valid_images_dir = os.path.join(FLAGS.data_folder, 'valid')\n",
    "\n",
    "    train_generator = ImageGenerator(train_images_dir, resnet50.preprocess_input)\n",
    "    valid_generator = ImageGenerator(valid_images_dir, resnet50.preprocess_input)\n",
    "\n",
    "    featurizer = resnet50.ResNet50(\n",
    "                weights = 'imagenet', \n",
    "                input_shape=(224,224,3), \n",
    "                include_top = False,\n",
    "                pooling = 'avg')\n",
    "\n",
    "    print(\"Generating bottleneck features\")\n",
    "    train_features = featurizer.predict_generator(train_generator, verbose=1)\n",
    "    train_labels = train_generator.get_labels()\n",
    "\n",
    "    valid_features = featurizer.predict_generator(valid_generator, verbose=1)\n",
    "    valid_labels = valid_generator.get_labels()\n",
    "    \n",
    "    # Create a classifier\n",
    "    model = fcn_classifier(input_shape=(2048,), units=FLAGS.units, l1=FLAGS.l1, l2=FLAGS.l2)\n",
    "    \n",
    "    # Start training\n",
    "    print(\"Starting training\")\n",
    "    model.fit(train_features, train_labels,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          shuffle=True,\n",
    "          validation_data=(valid_features, valid_labels))\n",
    "          \n",
    "    # Save the trained model to outp'uts which is a standard folder expected by AML\n",
    "    print(\"Training completed.\")\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    model_file = os.path.join(FLAGS.save_model_dir, 'model.hd5')\n",
    "    print(\"Saving model to: {0}\".format(model_file))\n",
    "    model.save(model_file)\n",
    "    \n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 32, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_integer('epochs', 10, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_integer('units', 512, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_float('l1', 0.01, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_float('l2', 0.01, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_string('data_folder', 'aerialsmall', \"Folder with training and validation images\")\n",
    "tf.app.flags.DEFINE_string('save_model_dir', './outputs', \"A folder for saving trained model\")\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    # get hold of the current run\n",
    "    run = Run.get_submitted_run()\n",
    "    train_evaluate(run)\n",
    "  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'keras-training-on-gpu-cluster'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create remote compute cluster\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in the workspace this code uses it and skips the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "batchai_cluster_name = ws.name + 'gpucluster'\n",
    "\n",
    "try:\n",
    "    # look for the existing cluster by name\n",
    "    compute_target = ComputeTarget(workspace=ws, name=batchai_cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('found compute target {}, just use it.'.format(batchai_cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(batchai_cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\", # GPU-based VM\n",
    "                                                                #vm_priority='lowpriority', # optional\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=1, \n",
    "                                                                cluster_max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, compute_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastore\n",
    "The dataset we will use for training has been uploaded to a public Azure blob storage container. We will register this container as the datastore with the workspace. This will create a connection to data for remote compute targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "datastore_name = 'aerialsmall'\n",
    "try:\n",
    "    ds = Datastore.register_azure_blob_container(workspace=ws, datastore_name=datastore_name,\n",
    "                                            container_name='aerialsmall',\n",
    "                                            account_name='azureailabs')\n",
    "    print('Creating new datastore')\n",
    "except:\n",
    "    ds = Datastore(ws, datastore_name)\n",
    "    print('Found existing datastore:', ds.name)\n",
    "   \n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure data access\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore=None, \n",
    "                   path_on_compute=datastore_name,\n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an estimator\n",
    "\n",
    "An estimator object is used to submit the training run.  Create the estimator by running the following code to define:\n",
    "\n",
    "* The name of the estimator object, `est`\n",
    "* The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for execution. \n",
    "* The compute target.  In this case you will use the Batch AI cluster you created\n",
    "* The training script name, train.py\n",
    "* Parameters required from the training script \n",
    "* Python packages needed for training\n",
    "\n",
    "In this tutorial, the target is the Batch AI cluster. All files in the script folder are uploaded into the cluster nodes for execution. The data_folder is set to use the datastore (`ds.as_download`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.as_download(),\n",
    "    '--l1': 0.01,\n",
    "    '--l2': 0.01,\n",
    "    '--units': 512,\n",
    "    '--epochs': 10\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                node_count=1,\n",
    "                process_count_per_node=1,\n",
    "                use_gpu=True,\n",
    "                pip_packages=['h5py','pillow','tensorflow-gpu']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job to the cluster\n",
    "\n",
    "Run the experiment by submitting the estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the call is asynchronous, it returns a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "### Monitor a remote run\n",
    "\n",
    "In total, the first run takes **approximately 10 minutes**. But for subsequent runs, as long as the script dependencies don't change, the same image is reused and hence the container start up time is much faster.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically. \n",
    "\n",
    "- **Running**: In this stage, the necessary scripts and files are sent to the compute target, then data stores are mounted/copied, then the entry_script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs.\n",
    "\n",
    "- **Post-Processing**: The ./outputs directory of the run is copied over to the run history in your workspace so you can access these results.\n",
    "\n",
    "\n",
    "You can check the progress of a running job in multiple ways. This tutorial uses a Jupyter widget as well as a `wait_for_completion` method. \n",
    "\n",
    "### Jupyter widget\n",
    "\n",
    "Watch the progress of the run with a Jupyter widget.  Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. \n",
    "\n",
    "Note: Currently, there is a problem with RunDetails widget in DSVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get log results upon completion\n",
    "\n",
    "Model training and monitoring happen in the background. Wait until the model has completed training before running more code. Use `wait_for_completion` to show when the model training is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display run results\n",
    "\n",
    "The training has completed. You can see the logs generated during the run by executing `Run.get_file_names()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model\n",
    "The last step in the training script wrote the file `model.hd5` in the directory named `outputs` in the VM of the cluster where the job is executed. `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. Hence, the model file is now also available in your workspace.\n",
    "\n",
    "You can register the model so that it can be later quried, examined and deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='aerial_classifier', model_path='outputs/model.hd5')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is ready for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
