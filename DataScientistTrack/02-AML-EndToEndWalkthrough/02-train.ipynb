{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Model Training\n",
    "In this section of the lab we will train a small fully connected neural network using the bottleneck features created in the previous part of the lab.\n",
    "\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/TLArch.png)\n",
    "\n",
    "We will use TensorFlow's Keras API to define the network and run training. \n",
    "\n",
    "We will run training on Azure Batch AI GPU cluster. After the model is trained, it will be registered in AML Model Registry.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/amlarch.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training script\n",
    "\n",
    "The script trains a simple network with one hidden layer. The input to the network is a vector of 2048 floating point numbers - the bottleneck features created in the previous step of the lab. The output layer consists of 6 units - representing six land type classes. To control overfitting the network uses a Dropout layer between the hidden layer and the output layer and L1 and L2 regularization in the output layer.\n",
    "\n",
    "The number of units in the hidden layer, L1 and L2 values, and batch size are all tuneable hyperparameters. The Dropout ratio is fixed at 0.5.\n",
    "\n",
    "Since the bottleneck feature files are small (as compared to original image datasets) they can be loaded into memory all at once. \n",
    "\n",
    "The trained model will be saved into the `./outputs` folder. This is one of the special folders in AML. The other one is the `./logs` folder. The content in these folders is automatically uploaded to the run history.\n",
    "\n",
    "The script uses AML `Run` object to track two performane measures: **training accuracy** and **validation accuracy**. The metrics are captured at the end of each epoch.\n",
    "\n",
    "#### Create a folder to hold the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Jupyter `%%writefile` magic to write the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Create custom callback to track accuracy measures in AML Experiment\n",
    "class RunCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.run.log(name=\"training_acc\", value=float(logs.get('acc')))\n",
    "        self.run.log(name=\"validation_acc\", value=float(logs.get('val_acc')))\n",
    "\n",
    "\n",
    "# Define network\n",
    "def fcn_classifier(input_shape=(2048,), units=512, classes=6,  l1=0.01, l2=0.01):\n",
    "    features = Input(shape=input_shape)\n",
    "    x = Dense(units, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=features, outputs=y)\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training regime\n",
    "def train_evaluate(run):\n",
    "   \n",
    "    print(\"Loading bottleneck features\")\n",
    "    train_file_name = os.path.join(FLAGS.data_folder, FLAGS.train_file_name)\n",
    "    valid_file_name = os.path.join(FLAGS.data_folder, FLAGS.valid_file_name)\n",
    "    \n",
    "    # Load bottleneck training features and labels\n",
    "    with h5py.File(train_file_name, \"r\") as hfile:\n",
    "        train_features = np.array(hfile.get('features'))\n",
    "        train_labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "        \n",
    "    # Load bottleneck validation features and labels\n",
    "    with h5py.File(valid_file_name, \"r\") as hfile:\n",
    "        valid_features = np.array(hfile.get('features'))\n",
    "        valid_labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "    # Create a network\n",
    "    model = fcn_classifier(input_shape=(2048,), units=FLAGS.units, l1=FLAGS.l1, l2=FLAGS.l2)\n",
    "    \n",
    "    run_callback = RunCallback(run)\n",
    "    \n",
    "    # Start training\n",
    "    print(\"Starting training\")\n",
    "    model.fit(train_features, train_labels,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          epochs=FLAGS.epochs,\n",
    "          shuffle=True,\n",
    "          validation_data=(valid_features, valid_labels),\n",
    "          callbacks=[run_callback])\n",
    "          \n",
    "    # Save the trained model to outp'uts which is a standard folder expected by AML\n",
    "    print(\"Training completed.\")\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    model_file = os.path.join('outputs', 'aerial_classifier.hd5')\n",
    "    print(\"Saving model to: {0}\".format(model_file))\n",
    "    model.save(model_file)\n",
    "    \n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 32, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_integer('epochs', 10, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_integer('units', 512, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_float('l1', 0.01, \"l1 regularization\")\n",
    "tf.app.flags.DEFINE_float('l2', 0.01, \"l2 regularization\")\n",
    "tf.app.flags.DEFINE_string('data_folder', './bottleneck', \"Folder with bottleneck features and labels\")\n",
    "tf.app.flags.DEFINE_string('train_file_name', 'aerial_bottleneck_train.h5', \"Training file name\")\n",
    "tf.app.flags.DEFINE_string('valid_file_name', 'aerial_bottleneck_valid.h5', \"Validation file name\")\n",
    "\n",
    "def main(argv=None):\n",
    "    # get hold of the current run\n",
    "    run = Run.get_submitted_run()\n",
    "    train_evaluate(run)\n",
    "  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AML workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "We will create a new experiment to manage training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'aerial-classifier-train'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create remote compute cluster\n",
    "\n",
    "We will use Azure Batch AI GPU cluster to run training and hyper parameter tuning.\n",
    "\n",
    "The cluster is set up for autoscaling. It will start with a single node and can scale to up to 4 nodes. The nodes are NC6 VMs with Tesla K80 GPU.\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in the workspace this code uses it and skips the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "batchai_cluster_name = ws.name + 'gpucls'\n",
    "vim_size = \"STANDARD_NC6\"\n",
    "\n",
    "try:\n",
    "    # look for the existing cluster by name\n",
    "    compute_target = ComputeTarget(workspace=ws, name=batchai_cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('found compute target {}, just use it.'.format(batchai_cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(batchai_cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=vim_size, # GPU-based VM\n",
    "                                                                #vm_priority='lowpriority', # optional\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=1, \n",
    "                                                                cluster_max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, compute_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastore\n",
    "\n",
    "The bottleneck files have been uploaded to the workspace's default datastore during the previous step. We will mount the store on the nodes of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an estimator\n",
    "\n",
    "As in the previous step of the lab, we will use **Estimator** to submit a run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('bottleneck').as_mount(),\n",
    "    '--l1': 0.001,\n",
    "    '--l2': 0.001,\n",
    "    '--units': 512,\n",
    "    '--epochs': 50\n",
    "}\n",
    "\n",
    "pip_packages = ['h5py','pillow','tensorflow-gpu']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                node_count=1,\n",
    "                process_count_per_node=1,\n",
    "                use_gpu=True,\n",
    "                pip_packages=pip_packages\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the job\n",
    "\n",
    "Run the experiment by submitting the estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the call is asynchronous, it returns a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "### Monitor a remote run\n",
    "\n",
    "In total, the first run takes **approximately 10 minutes**. But for subsequent runs, as long as the script dependencies don't change, the same image is reused and hence the container start up time is much faster.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically. \n",
    "\n",
    "- **Running**: In this stage, the necessary scripts and files are sent to the compute target, then data stores are mounted/copied, then the entry_script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs.\n",
    "\n",
    "- **Post-Processing**: The ./outputs directory of the run is copied over to the run history in your workspace so you can access these results.\n",
    "\n",
    "\n",
    "You can check the progress of a running job in multiple ways. This tutorial uses a Jupyter widget as well as a `wait_for_completion` method. \n",
    "\n",
    "### Jupyter widget\n",
    "\n",
    "Watch the progress of the run with a Jupyter widget.  Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. \n",
    "\n",
    "Note: Currently, there is a problem with RunDetails widget in DSVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get log results upon completion\n",
    "\n",
    "Model training and monitoring happen in the background. Wait until the model has completed training before running more code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display run results\n",
    "\n",
    "The training has completed. You can see the logs generated during the run by executing `Run.get_file_names()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "As you can see on **Training Accuracy** and **Validation Accuracy** charts, the validation accuracy reaches a plateau while the training accuracy keeps climbing. This is an indication overfitting. We may need to fine tune hyperparameters to achieve better performance.\n",
    "\n",
    "As described before, our network has 4 hyperparameters: \n",
    "- Number of units in the hidden layer\n",
    "- L1 and L2 regularization, and\n",
    "- mini-batch size.\n",
    "\n",
    "So far we have executed a single training run on one set of hyperparameters. \n",
    "\n",
    "Now, we are going to use AML feature called *hyperdrive* to launch multiple runs on multiple cluster nodes using different combinations of hyperparameter values.\n",
    "\n",
    "As we have limited time to complete the lab, we are going to limit a number of hyperparameter combinations.\n",
    "\n",
    "First, let's define the hyperparameter space using grid sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "ps = GridParameterSampling(\n",
    "    {\n",
    "        '--units': choice(256, 512),\n",
    "        '--l1': choice(0.001, 0.01, 0.05),\n",
    "        '--l2': choice(0.001, 0.01, 0.05)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new estimator without the above parameters since they will be passed in later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--data_folder': ds.path('bottleneck').as_mount(),\n",
    "    '--epochs': 50\n",
    "}\n",
    "\n",
    "pip_packages = ['h5py','pillow','tensorflow-gpu']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                node_count=1,\n",
    "                process_count_per_node=1,\n",
    "                use_gpu=True,\n",
    "                pip_packages=pip_packages\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperdrive* supports early termination policies to limit exploration of hyperparameter combinations that don't show promise of helping reach the target metric. This is feature is especially useful when traversing large hyperparameter spaces. Since we are going to run a small number of jobs we will not apply early termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = NoTerminationPolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric as *validation_acc* that's recorded in our training runs. If you go back to visit the training script, you will notice that this value is being logged after every epoch. We also want to tell the service that we are looking to maximizing this value. We also set the number of total runs to 20, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps,\n",
    "                          policy=policy,\n",
    "                          primary_metric_name='validation_acc', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=12,\n",
    "                          max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new experiment to capture `hyperdrive` runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'aerial-classifier-hyperdrive'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = exp.submit(config=htc)\n",
    "hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr.wait_for_completion(show_output=True) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and register best model\n",
    "When all the jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Validation Accuracy:', best_run_metrics['validation_acc'])\n",
    "print('\\n Units:',parameter_values[5])\n",
    "print('\\n L1:',parameter_values[7])\n",
    "print('\\n L2:',parameter_values[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output of the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model\n",
    "The last step in the training script wrote the file `aerial_classifier.hd5` in the `outputs` directory. As noted before, `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. \n",
    "\n",
    "You can register the model so that it can be later queried, examined and deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='aerial_classifier', model_path='outputs/aerial_classifier.hd5')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "The model is ready for deployment. Continue to `deploy.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
