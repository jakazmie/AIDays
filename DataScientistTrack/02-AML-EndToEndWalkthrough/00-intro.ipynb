{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Lab Overview and Setup\n",
    "This lab demonstrates how to use Azure Machine Learning service to orchestrate an end-to-end Deep Learning workflow from data preparation to model operationalization.\n",
    "\n",
    "\n",
    "## Scenario\n",
    "\n",
    "We will train a custom image classification model to automatically classify the type of land shown in aerial images of 224-meter x 224-meter plots. Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery. The images used in this lab are based on imagery from the U.S. National Land Cover Database. U.S. National Land Cover Database defines six primary classes of land use: *Developed*, *Barren*, *Forested*, *Grassland*, *Shrub*, *Cultivated*. Example images in each land use class are shown here:\n",
    "\n",
    "Developed | Cultivated | Barren\n",
    "--------- | ------ | ----------\n",
    "![Developed](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/developed1.png) | ![Cultivated](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/cultivated1.png) | ![Barren](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/barren1.png)\n",
    "\n",
    "Forested | Grassland | Shrub\n",
    "---------| ----------| -----\n",
    "![Forested](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/forest1.png) | ![Grassland](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/grassland1.png) | ![Shrub](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/shrub1.png)\n",
    "\n",
    "We are going to employ a machine learning technique called transfer learning. Transfer learning is one of the fastest (code and run-time-wise) ways to start using deep learning. It allows to reuse knowledge gained while solving one problem to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. Transfer Learning makes it feasible to train very effective ML models on relatively small training data sets, which is our case.\n",
    "\n",
    "Although the primary goal of this lab is to understand how to use Azure ML to orchestrate Deep Learning workflows rather then to dive into Deep Learning techniques, ask the instructor if you want to better understand the approach utilized in the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab flow\n",
    "\n",
    "During the lab we will walk through a full end-to-end machine learning workflow.\n",
    "\n",
    "![AMLWorkflow](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/aml.png)\n",
    "\n",
    "- First, we will pre-process training images using a pretrained Deep Neural Network to extract a relatively small number of powerfull features - so called bottleneck features. \n",
    "\n",
    "- Then we will use the extracted bottleneck features to train a small Fully Connected Neural Network to recognize land plot images.\n",
    "\n",
    "- Finally, we will operationalize the  model as a REST web service and deploy it to Azure.\n",
    "\n",
    "Each part of the lab runs as a Jupyter notebook:\n",
    "\n",
    "* Part 1 - Feature extraction - `01-feature-engineering.ipynb`\n",
    "* Part 2 - Training and evaluation - `02-train.ipynb`\n",
    "* Part 3 - Model operationalization - `03-deploy.ipynb`\n",
    "\n",
    "We will use Azure Machine Learning service and Azure compute and storage resources to orchestrate this workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is Azure Machine Learning service?\n",
    "\n",
    "Azure Machine Learning service is a cloud service that you can use to develop and deploy machine learning models. Using Azure Machine Learning service, you can track your models as you build, train, deploy, and manage them, all at the broad scale that the cloud provides.\n",
    "\n",
    "Azure Machine Learning service fully supports open-source technologies, so you can use tens of thousands of open-source Python packages with machine learning components such as TensorFlow, PyTorch, MXNet and scikit-learn. \n",
    "\n",
    "In this lab, you are going to use TensorFlow, specifically TensorFlow's high level API Keras.\n",
    "\n",
    "Azure Machine Learning service helps you orchestrate machine learning workflows using an architecture depicted on the below diagram.\n",
    "\n",
    "![AML workflow](https://github.com/jakazmie/AIDays/raw/master/DataScientistTrack/02-AML-EndToEndWalkthrough/images/amlarch.png)\n",
    "\n",
    "\n",
    "1. Data preparation and model training logic are coded as Python scripts utilizing any the hundreds of supported libraries nd frameworks. The scripts can be instrumented with AML API calls to help with capturing and managing records of training runs, such as performance measures, logs, serialized models, etc.\n",
    "\n",
    "2. The scripts can execute in your local environment or on a remote Compute Target. You would usually do code development and debugging in your local environment using a small development dataset and train on a full training dataset on a remote Compute Target. The primary remote targets are Azure VMs and Azure Batch AI clusters. The training and validation data accessed by Compute Targets is stored in AML Datastores that are backed up by Azure Blob Storage or Azure Data Lake.\n",
    "\n",
    "3. As you run training iterations - a.k.a. runs, run records are stored in Azure ML service Experiment. You can query the Experiment's content using Python APIs or browser through it using Azure Portal.\n",
    "\n",
    "4. When your model is ready for deployment you register it in Model Registry. Model Registry maintains versions of the model including the model's serialized files and metadata.\n",
    "\n",
    "5. Depending on you deployment target, AML will create an optimized docker image and store it in private Azure Container Registry. The image includes the model, the scoring file to invoke the model, and all required runtime dependencies.\n",
    "\n",
    "6. The image can be deployed to any of the supported targets including Azure Container Instance, Azure Kubernetes Services, or Azure IoT Edge. \n",
    "\n",
    "\n",
    "All Azure ML components are managed within a top level container - Azure Machine Learning Workspace. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Azure Machine Learning Workspace\n",
    "\n",
    "In this step, you will provision and configure Azure ML Workspace that will be used throughout the lab.\n",
    "\n",
    "You can create AML Workspace using AML Python SDK, AML CLI, or Azure Portal. The below Jupyter cell shows the Python SDK code to create the workspace.\n",
    "\n",
    "Replace the placeholders in the code below with your values for Azure subscription ID, a workspace name, a resource group name, and a region. \n",
    "\n",
    "When you execute the cell you will be asked to log in to Azure. Follow the printed instructions and use your Azure credentials to complete authentication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note. We have observed issues with Python SDK `Workspace` API. As a temporary workaround, create the workspace in Azure Portal and then execute the below cell.***\n",
    "\n",
    "***Use this URL to create the workspace in Azure Portal***\n",
    "\n",
    "https://ms.portal.azure.com/#create/Microsoft.MachineLearningServices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "subscription_id ='<your subscription id>'\n",
    "resource_group ='<your resource group>'\n",
    "workspace_name = '<your workspace name>'\n",
    "workspace_region = '<your region>'\n",
    "    \n",
    "try:\n",
    "   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "\n",
    "   print('Workspace configuration succeeded. You are all set!')\n",
    "except:\n",
    "   print('Workspace not found. Creating...')\n",
    "   ws = Workspace.create(name = workspace_name,\n",
    "                subscription_id = subscription_id,\n",
    "                resource_group = resource_group, \n",
    "                location = workspace_region,\n",
    "                create_resource_group = True,\n",
    "                exist_ok = True)\n",
    "\n",
    "ws.get_details()\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "Your AML Workspace is ready and the configuration has been written to a json config file. You can now proceed to the first part of the lab - Feature Extraction.\n",
    "\n",
    "Start `01-feature-engineering.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
