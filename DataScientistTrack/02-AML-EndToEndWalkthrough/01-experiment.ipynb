{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow training on Azure GPU VM.\n",
    "This notebook demonstrates how to use Azure Machine Learning service to orchestrate an end-to-end Machine Learning workflow from data preparation to model operationalization.\n",
    "\n",
    "\n",
    "## Scenario\n",
    "\n",
    "We will train a custom image classification model to automatically classify the type of land shown in aerial images of 224-meter x 224-meter plots. Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery. The images used in this lab are based on imagery from the U.S. National Land Cover Database. U.S. National Land Cover Database defines six primary classes of land use: *Developed*, *Barren*, *Forested*, *Grassland*, *Shrub*, *Cultivated*. Example images in each land use class are shown here:\n",
    "\n",
    "Developed | Cultivated | Barren\n",
    "--------- | ------ | ----------\n",
    "![Developed](images/developed1.png) | ![Cultivated](images/cultivated1.png) | ![Barren](images/barren1.png)\n",
    "\n",
    "Forested | Grassland | Shrub\n",
    "---------| ----------| -----\n",
    "![Forested](images/forest1.png) | ![Grassland](images/grassland1.png) | ![Shrub](images/shrub1.png)\n",
    "\n",
    "We are going to employ a machine learning technique called transfer learning. Transfer learning is one of the fastest (code and run-time-wise) ways to start using deep learning. It allows to reuse knowledge gained while solving one problem to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. Transfer Learning makes it feasible to train very effective ML models on relatively small training data sets, which is our case.\n",
    "\n",
    "Although the primary goal of this lab is to understand how to use Azure ML to orchestrate TensorFlow training rather then to dive into Deep Learning techniques, ask the instructor if you want to better understand the approach utilized in the lab in more detail.\n",
    "\n",
    "![Transfer Learing](images/TransferL.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab flow\n",
    "\n",
    "During the lab we will walk through the full end-to-end machine learning workflow.\n",
    "\n",
    "![MLWorkflow](images/MLWorkflow.png)\n",
    "\n",
    "\n",
    "- We will first develop data preparation and modeling routines in a local development environment, using a small development set of images to experiment and to understand the code. \n",
    "\n",
    "- After the code has been validated we will use Azure ML to deploy and run the data preparation and training scripts on Azure GPU cluster. We will run a number of concurrent training jobs to fine tune the model's hyper parameters\n",
    "\n",
    "- Finally, we will operationalize the best performing version of the model.\n",
    "\n",
    "\n",
    "We will use Azure Machine Learning service to orchestrate the above workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the development dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialtar/aerialtiny.tar.gz\n",
    "tar -xzf aerialtiny.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bottleneck features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **ResNet50** DNN, pre-trained on the ImageNet dataset to extract features from input images. We will only instantiate the convolutional part of **ResNet50**, everything up to the fully-connected layers. We will then run this \"stripped down\" network (a.k.a featurizer) on training and validation images and store the output - the so called bottleneck features - in memory. Then we will train a small fully connected neural network on the bottleneck features. The output of the featurizer is a vector of 2048 numbers, resulting in a very small data set as compared to the original image dataset. As such, it is feasible to store it in memory. \n",
    "\n",
    "To feed data into the featurizer we will implement a custom generator class - `ImageGenerator`. It will yield batches of images - as Numpy arrays - preprocessed to the format required by `ResNet50` - Caffe style image encoding. Although, we could load all images from the small development set into memory, this approach would not scale to the larger data set we will be using later in the lab. As such we need a method of reading and pre-processing images in smaller batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# This is a generator that yields batches of preprocessed images\n",
    "class ImageGenerator(tf.keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, img_dir, preprocess_fn=None, batch_size=64):\n",
    "        \n",
    "        # Create the dictionary that maps class names into numeric labels \n",
    "        folders = os.listdir(img_dir)\n",
    "        folders.sort()\n",
    "        indexes = range(len(folders))\n",
    "        label_map = {key: value for (key, value) in zip(folders, indexes)}\n",
    "        self.num_classes = len(label_map)\n",
    "        \n",
    "        # Create a list of all images in a root folder with associated numeric labels\n",
    "        labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                              for folder in folders \n",
    "                              for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                              ]\n",
    "        # Shuffle the list\n",
    "        random.shuffle(labeled_image_list)\n",
    "        # Set image list and associated label list\n",
    "        self.image_list, self.label_list = zip(*labeled_image_list) \n",
    "        # Set batch size\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "        # Set the pre-processing function passed as a parameter\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "        # Set number of batches\n",
    "        self.n_batches = len(self.image_list) // self.batch_size\n",
    "        if len(self.image_list) % self.batch_size > 0:\n",
    "            self.n_batches += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pathnames = self.image_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images = self.__load_images(pathnames)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Load a set of images passed as a parameter into a NumPy array\n",
    "    def __load_images(self, pathnames):\n",
    "        images = []\n",
    "        for pathname in pathnames:\n",
    "            img = image.load_img(pathname, target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        images = np.asarray(images)\n",
    "        if self.preprocess_fn != None:\n",
    "            images = self.preprocess_fn(images)   \n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Return labels in one-hot encoding\n",
    "    def get_labels(self):\n",
    "        \n",
    "        return to_categorical(np.asarray(self.label_list), self.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bottleneck featurs\n",
    "\n",
    "train_images_dir = 'aerialtiny/train'\n",
    "valid_images_dir = 'aerialtiny/valid'\n",
    "\n",
    "train_generator = ImageGenerator(train_images_dir, resnet50.preprocess_input)\n",
    "valid_generator = ImageGenerator(valid_images_dir, resnet50.preprocess_input)\n",
    "\n",
    "featurizer = resnet50.ResNet50(\n",
    "            weights = 'imagenet', \n",
    "            input_shape=(224,224,3), \n",
    "            include_top = False,\n",
    "            pooling = 'avg')\n",
    "\n",
    "train_features = featurizer.predict_generator(train_generator, verbose=1)\n",
    "train_labels = train_generator.get_labels()\n",
    "\n",
    "valid_features = featurizer.predict_generator(valid_generator, verbose=1)\n",
    "valid_labels = valid_generator.get_labels()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate\n",
    "\n",
    "At this point, we have training and validation features and training and validation labels in in-memory Numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define, train and evaluate a small fully connected neural network on top of bottleneck features. We will encapsulate the network architecture in a utility function that takes a set of hyperparameters as input. This will make it easier to experiment with different hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "\n",
    "def fcn_classifier(input_shape=(2048,), units=512, classes=6,  l1=0.01, l2=0.01):\n",
    "    features = Input(shape=input_shape)\n",
    "    x = Dense(units, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=features, outputs=y)\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to instantiate the model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_classifier(input_shape=(2048,), units=1024, l1=0.006, l2=0.006)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_features, train_labels,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          shuffle=True,\n",
    "          validation_data=(valid_features, valid_labels))\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code is now debugged and ready. We will now move to the next part of the lab in which we are going to use Azure Machine Learning service to train the model on a larger dataset using Azure GPU VM and then deploy the model to Azure Kubernetes Service."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
